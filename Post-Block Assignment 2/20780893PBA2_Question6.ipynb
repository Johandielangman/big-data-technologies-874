{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"bdt-a3","language":"python","name":"bdt-a3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"20780893PBA2_Question6.ipynb","provenance":[{"file_id":"https://github.com/jackdotwa/us-ie-big-data-technologies/blob/master/map-reduce/termvect/map-reduce-term-vector-simple.ipynb","timestamp":1638187683535}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"xBko6Q9QEKFz"},"source":["# Question 6\n","***\n","JG Hanekom <br>\n","20780893 <br>\n","December <br>\n","***"]},{"cell_type":"markdown","metadata":{"id":"SeX7ZihpmDc6"},"source":["# Map Reduce\n","\n","This notebook is performing map reduce in a simplified manner in Python. Distribution of compute to different nodes is not done here; the purpose rather is to explore how to implement a map or reduce function, assuming that the functionality is provided akin to the libraries mentioned in [Dean and Ghemawat](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf).\n","\n","\n","This notebook comprises a section defining identity mappers and reducers, along with a `run` method which you may change if necessary. An intermediate sort function is also provided. \n","\n","Implement the `mapper` and `reducer` in the Term Vectors section, and use the run cell as provided.\n"]},{"cell_type":"code","metadata":{"id":"ciO3rL9fmDc8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638516576923,"user_tz":-120,"elapsed":1804,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}},"outputId":"86005e81-275d-46a7-f43c-b106e2f8e9e9"},"source":["from itertools import groupby\n","from operator import itemgetter\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from collections import Counter\n","%config Completer.use_jedi = False\n","import requests\n","from urllib.parse import urlsplit"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n","  \n"]}]},{"cell_type":"markdown","metadata":{"id":"Agmsop3ZbGhq"},"source":["### Define URL's\n","Will be using the following movie scripts as URL's"]},{"cell_type":"code","metadata":{"id":"y2kWS-SwbDcH","executionInfo":{"status":"ok","timestamp":1638516576924,"user_tz":-120,"elapsed":14,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["shrek_movie_url = \"https://raw.githubusercontent.com/mackenziedg/shrek/master/data/shrek3.txt\"\n","bee_movie_url = \"https://gist.githubusercontent.com/ElliotGluck/64b0b814293c09999f765e265aaa2ba1/raw/79f24f9f87654d7ec7c2f6ba83e927852cdbf9a5/gistfile1.txt\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzx0iuxzbK9X"},"source":["### Define the function that will clean the text files"]},{"cell_type":"code","metadata":{"id":"XlJcmGPQujWk","executionInfo":{"status":"ok","timestamp":1638516576926,"user_tz":-120,"elapsed":15,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["def cleaner(line):\n","    # lowercase all words and get alphabetical char only and keeping\n","    # apostrophe for time being\n","    words = re.findall(r'[a-z\\']+' , line.lower())\n","    for word in words :\n","        # we will omit apostrophe ' s assuming users won't type them in a search\n","        word = word.replace(\"'\" , '')\n","        if not (word is '' or word in stopwords.words('english')):\n","            yield word"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cla0QroKpkHL"},"source":["### Define a function to extract a hostname\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"GmflKN5wpn03","executionInfo":{"status":"ok","timestamp":1638516576926,"user_tz":-120,"elapsed":15,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}},"outputId":"32e0acc2-6738-4656-9c8e-6609add4951e"},"source":["def get_url(url):\n","  return \"{0.netloc}\".format(urlsplit(url))\n","\n","url = \"http://stackoverflow.com/questions/9626535/get-domain-name-from-url\"\n","get_url(url)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'stackoverflow.com'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"1TmMb0L2bTdk"},"source":["### Define the Mapper\n","The mapper will \n","1. Clean the data\n","2. Count the words\n","3. Filter out words with only one count"]},{"cell_type":"code","metadata":{"id":"mATQxeFqmDc-","executionInfo":{"status":"ok","timestamp":1638516576926,"user_tz":-120,"elapsed":13,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["def mapper(key, value):\n","    \"\"\"\n","    The mapper will extract the hostname from the url, count the words\n","    and only return those with more than 1 word.\n","    : param key : Raw url \n","    : param value : Document text\n","    \"\"\"\n","    r = dict(Counter(cleaner(value)))\n","    r2 = [(k, v) for k, v in r.items() if v >= 2]\n","    yield (get_url(key), r2)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIhw-7wrsWCg"},"source":["### Define the reducer"]},{"cell_type":"code","metadata":{"id":"xL_kHjJWmDc_","executionInfo":{"status":"ok","timestamp":1638516576928,"user_tz":-120,"elapsed":13,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["def reducer(key , list_value):\n","    \"\"\"\n","    User defined reducer. This reducer will return the top 10 most frequently \n","    used words.\n","    : param key : The hostname of the document\n","    : param list_value : The term vector\n","    \"\"\"\n","    yield (key, list_value[:10])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJ3M2tn6r4PJ"},"source":["### Define an intermediate sort function"]},{"cell_type":"code","metadata":{"id":"CLgIHxQar7qe","executionInfo":{"status":"ok","timestamp":1638516576929,"user_tz":-120,"elapsed":14,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["def intermediate_sort(data):\n","    \"\"\"\n","    This sorts the term vector in a descending order\n","    \"\"\"\n","    result = []\n","    for v in data:\n","      result.append((v[0], sorted(v[1], key=itemgetter(1), reverse=True)))\n","    return result"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RV6BwEOcr9W0"},"source":["### Define the run"]},{"cell_type":"code","metadata":{"id":"JjUOi7L8mDdA","executionInfo":{"status":"ok","timestamp":1638516576929,"user_tz":-120,"elapsed":14,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}}},"source":["def run(sources_dict):\n","    \"\"\"\n","    The run function will run the mapper, reducer and intermediate sort ans save the results as lists.\n","    : param sources_dict : dictionary where (url,page), for example ('www.github.com/','file.txt')\n","    \"\"\"\n","\n","    # Define empty result lists\n","    map_result =[]\n","    reduce_result =[]\n","\n","    # Open the documents and pass to mapper\n","    for k , v in sources_dict.items(): \n","        f = requests.get(k+v)\n","        map_result += list(mapper(k, f.text))\n","   \n","    # Do an intermediate sort\n","    intermediate_result = intermediate_sort(map_result)\n","\n","    # Pass to the reducer\n","    for elem in intermediate_result:\n","        reduce_result.append(list(reducer(elem[0], elem[1])))\n","    return map_result, intermediate_result, reduce_result"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b9GDuXNrxVf"},"source":["### Run the mapreduce query"]},{"cell_type":"code","metadata":{"id":"qAGOsk79mDdB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638516580503,"user_tz":-120,"elapsed":3588,"user":{"displayName":"Johan Hanekom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Fzkfth2P01Phtp-uxcBkzMcIgtB5KeVrb9Dp=s64","userId":"10588170236408608666"}},"outputId":"b3bfec43-21a6-401c-c523-d834df7a330d"},"source":["x, y, res = run({'https://raw.githubusercontent.com/mackenziedg/shrek/master/data/': \"shrek3.txt\" , 'https://gist.githubusercontent.com/ElliotGluck/64b0b814293c09999f765e265aaa2ba1/raw/79f24f9f87654d7ec7c2f6ba83e927852cdbf9a5/': \"gistfile1.txt\"})\n","\n","# Return the reducer results\n","res"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[('raw.githubusercontent.com',\n","   [('shrek', 647),\n","    ('charming', 220),\n","    ('donkey', 212),\n","    ('artie', 208),\n","    ('prince', 207),\n","    ('puss', 194),\n","    ('fiona', 181),\n","    ('third', 121),\n","    ('script', 120),\n","    ('final', 119)])],\n"," [('gist.githubusercontent.com',\n","   [('bee', 93),\n","    ('im', 80),\n","    ('dont', 64),\n","    ('bees', 58),\n","    ('know', 53),\n","    ('barry', 50),\n","    ('honey', 49),\n","    ('right', 43),\n","    ('thats', 41),\n","    ('youre', 40)])]]"]},"metadata":{},"execution_count":9}]}]}